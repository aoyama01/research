hist(data1,main="mu=0,sig=1",xlim=c(-8,8))
abline(v=0,col=2)
#2つ目
hist(data2,main="mu=2,sig=1",xlim=c(-8,8))
abline(v=0,col=2)
#3つ目
hist(data3,main="mu=0,sig=2",xlim=c(-8,8))
abline(v=0,col=2)
for(j in 1:3){#j=1,2,3,それぞれでhistgramを表示させる
hist(mean.samp[j,],xlab="xmean",main=paste0("n=",nvec[j]),col="lightgoldenrod1")
}
hist(mean.samp[j,],xlab=" xmean",main=paste0("n=",nvec[ j]),
col="lightgoldenrod1")
#結果保存のための空の行列(3パターンx実験回数)
random.sample　
random.sample　
mean(random.sample)
mean(random.sample)
##histgramの表示
par(mfrow=c(1,3))#1画面に3つのhistgramを表示させる
for(j in 1:3){#j=1,2,3,それぞれでhistgramを表示させる
hist(mean.samp[j,],xlab="xmean",main=paste0("n=",nvec[j]),col="lightgoldenrod1")
}
n=1000 #乱数生成数を1000個にセット
#3パターンそれぞれで1000個の乱数生成
data1=rnorm(n,mean=0,sd=1) #sdは標準偏差
data2=rnorm(n,mean=2,sd=1)
data3=rnorm(n,mean=0,sd=2)
par(mfrow=c(1,3)) #1画面にhistgramを3枚出す
#1つ目
hist(data1,main="mu=0,sig=1",xlim=c(-8,8))
abline(v=0,col=2)
#2つ目
hist(data2,main="mu=2,sig=1",xlim=c(-8,8))
abline(v=0,col=2)
#3つ目
hist(data3,main="mu=0,sig=2",xlim=c(-8,8))
abline(v=0,col=2)
nvec=c(10,50,500) #実験する3パターン
p=0.1 #ベルヌーイ試行の成功確率
sim.times=10000 #実験回数
mean.samp=matrix(NA,3,sim.times)
#結果保存のための空の行列(3パターンx実験回数)
for(j in 1:3){#j=1,2,3 (全3パターン)それぞれで以下の手順を繰り返す)
n=nvec[j] #3パターンのうち1つを選ぶ
for(d in 1:sim.times){ #d=1,2,...,10000,それぞれで以下の手順を繰り返す
random.sample=sample(c(0,1), n, prob = c(1-p,p), replace=TRUE)
mean.samp[j,d]=mean(random.sample)
}
}
##histgramの表示
par(mfrow=c(1,3))#1画面に3つのhistgramを表示させる
for(j in 1:3){#j=1,2,3,それぞれでhistgramを表示させる
hist(mean.samp[j,],xlab="xmean",main=paste0("n=",nvec[j]),col="lightgoldenrod1")
}
#j=1の場合のみ
nvec=c(10,50,500) #実験する3パターン
p=0.1 #ベルヌーイ試行の成功確率
sim.times=100 #実験回数(スライドの10000回を100回に減らした)
mean.samp=matrix(NA,3,sim. times)
#結果保存のための空の行列(3パターンx実験回数)
j=1
n=nvec[j] #3パターンのうち，j=1番目を選ぶ
for(d in 1:sim.times){ #d=1,2,...,10000, それぞれで以下の手順を繰り返す
random.sample=sample(c(0,1),n, prob = c(1-p,p),replace=TRUE)
mean.samp[j,d]=mean(random. sample)
}
hist(mean.samp[j,],xlab=" xmean",main=paste0("n=",nvec[ j]),
col="lightgoldenrod1")
random.sample
mean(random.sample)
alpha=0.05 #信頼係数
#####標本1#####
n1=5 #標本1のデータ数
dat1=c(8.43,6.92,9.78,9.19,11.27)
xbar1 <- mean(dat1) #標本Aの平均を計算
sig1 <- var(dat1)#標本Aの不偏分散を計算
tval1=qt(1-alpha/2,df=n1-1) #自由度n1-1のt分布の0.975確率点をとる
L1=xbar1-tval1*sqrt(sig1/n1) #区間の下限
U1=xbar1+tval1*sqrt(sig1/n1) #区間の上限
####標本Aと同様に，標本Bの信頼区間の下限，上限を求める####
n2=15 #標本Bのデータ数
dat2=c(6.08,7.41,8.52,5.70,8.39,8.06,8.17,10.23,5.56,10.53,
6.51,5.74,6.57,8.51,8.30)
xbar2=mean(dat2) #標本Bの平均を計算
sig2=var(dat2) #標本Bの不偏分散を計算
tval2=qt(1-alpha/2,df=n2-1) #自由度n2-1のt分布の0.975確率点をとる（本で調べてもOK）
L2=xbar2-tval2*(sig2/n2) #標本2の区間の下限
U2=xbar2+tval2*(sig2/n2) #標本2の区間の上限
####2つの信頼区間をplot####
dotchart(c(xbar2,xbar1),pch = 16, xlim=range(dat1,dat2),xlab="")
arrows(L1,2,U1,2,length=0.05,angle=90,code=3)
arrows(L2,1,U2,1,length=0.05,angle=90,code=3,col=2)
mtext(c("B","A"),side=2,at=1:2,line=0.5,las=1)
(xbar1)
(xbar2)
(sig1)
(sig2)
(tval1=qt(1-alpha/2,df=n1-1))
(tval2=qt(1-alpha/2,df=n2-1))
>     ####2つの信頼区間をplot####
> dotchart(c(xbar2,xbar1),pch = 16, xlim=range(dat1,dat2),xlab="")
> arrows(L1,2,U1,2,length=0.05,angle=90,code=3)
> arrows(L2,1,U2,1,length=0.05,angle=90,code=3,col=2)
> mtext(c("B","A"),side=2,at=1:2,line=0.5,las=1)
####2つの信頼区間をplot####
dotchart(c(xbar2,xbar1),pch = 16, xlim=range(dat1,dat2),xlab="")
arrows(L1,2,U1,2,length=0.05,angle=90,code=3)
arrows(L2,1,U2,1,length=0.05,angle=90,code=3,col=2)
mtext(c("B","A"),side=2,at=1:2,line=0.5,las=1)
(xbar1)
x = c(0.34, 0.41, 0.32, 0.52, 0.42, 0.32, 0.43, 0.45, 0.44, 0.36)
(sum((x-xbar)^2))
(sum((x-mean(x))^2))
(sqrt(25))
x = c(0.34, 0.41, 0.32, 0.52, 0.42, 0.32, 0.43, 0.45, 0.44, 0.36)
y = c(0.37, 0.33, 0.30, 0.25, 0.35, 0.32, 0.32, 0.35, 0.35, 0.34, 0.35, 0.34, 0.32, 0.26, 0.34)
xbar=mean(x); ybar=mean(y) #標本1,2それぞれの平均
n1=length(x); n2=length(y) #標本1,2それぞれの標本数
u=sqrt((sum((x-xbar)^2)+sum((y-ybar)^2))/(n1+n2-2)) #標本1,2で共通の不偏分散
#統計量の実現値
(T0 = (xbar-ybar)/sqrt(u^2*(1/n1+1/n2)))
#自由度dfの上側α/2確率点
alp = 0.5
(qt(alp/2, df=n1+n2-2))
(qt(1-alp/2, df=n1+n2-2))
t.test(x, y)
x = c(0.34, 0.41, 0.32, 0.52, 0.42, 0.32, 0.43, 0.45, 0.44, 0.36)
y = c(0.37, 0.33, 0.30, 0.25, 0.35, 0.32, 0.32, 0.35, 0.35, 0.34, 0.35, 0.34, 0.32, 0.26, 0.34)
xbar=mean(x); ybar=mean(y) #標本1,2それぞれの平均
n1=length(x); n2=length(y) #標本1,2それぞれの標本数
u=sqrt((sum((x-xbar)^2)+sum((y-ybar)^2))/(n1+n2-2)) #標本1,2で共通の不偏分散
#統計量の実現値
(T0 = (xbar-ybar)/sqrt(u^2*(1/n1+1/n2)))
#自由度dfの上側α/2（下側1-α/2）確率点
alp = 0.05
(qt(1-alp/2, df=n1+n2-2))
x = c(0.34, 0.41, 0.32, 0.52, 0.42, 0.32, 0.43, 0.45, 0.44, 0.36)
y = c(0.37, 0.33, 0.30, 0.25, 0.35, 0.32, 0.32, 0.35, 0.35, 0.34, 0.35, 0.34, 0.32, 0.26, 0.34)
##計算用定義
xbar=mean(x); ybar=mean(y) #標本1,2それぞれの平均
n1=length(x); n2=length(y) #標本1,2それぞれの標本数
u1=var(x); u2=var(y) #標本1,2それぞれの不偏分散
##Welch test statistics
sig=u1/n1+u2/n2 #分散部分だけ先定義
(W0=(xbar-ybar)/sqrt(sig)) #Welchの検定統計量
##t値
(df=(sig^2)/(((u1/n1)^2/(n1-1))+((u2/n2)^2/(n2-1))))#自由度
##自由度dfの上側α/2（下側1-α/2）確率点
alp=0.05
(qt(1-alp/2,df=df))
(qt(1-alp/2,df=12))
#データ入力
x=c(151.35,160.52,154.81,157.77,163.40,157.96,152.08,159.96,158,83,159.88)
y=c(21.68,22.94,22.57,23.03,24.66,24.24,20.72,21.67,23.67,23.58,24.24)
ploy(x,y)
plot(x,y)
n=length(x)
(Sxy=sum(x*y)/n-maen(x)*mean(y))
(Sxy=sum(x*y)/n-mean(x)*mean(y))
(Sxx=sum(x^2)/n-mean(x)^2)
(Syy=sum(y^2)/n-mean(y)^2)
(beta1=Sxy/Sxx)
(beta0=mean(y)-beta1*mean(x))
#誤差分散の推定量の計算
(Se=n*Syy*(1-(Sxy^2/(Sxx*Syy))))
(sighat=Se/(n-2))
#信頼区間
alp=0.05; dff=n-2
tval=qt(1-alp/2,dff)
(L=beta1-tval*sqrt(sighat/(n+Sxx)))
(L=beta1+tval*sqrt(sighat/(n+Sxx)))
#検定
(teststats=beta1/sqrt(sighat/(n*Sxx)))
#信頼区間
alp=0.05; dff=n-2
tval=qt(1-alp/2,dff)
(L=beta1-tval*sqrt(sighat/(n+Sxx)))
(U=beta1+tval*sqrt(sighat/(n+Sxx)))
#検定
(teststats=beta1/sqrt(sighat/(n*Sxx)))
#臨界点
alp=0.05; dff=n-2
(tval=qt(1-alp/2,dff))
#データ入力
x=c(151.35,160.52,154.81,157.77,163.40,157.96,152.08,159.96,158,83,159.88)
y=c(21.68,22.94,22.57,23.03,24.66,24.24,20.72,21.67,23.67,23.58,24.24)
plot(x,y)
n=length(x)
(Sxy=sum(x*y)/n-mean(x)*mean(y))
(Sxx=sum(x^2)/n-mean(x)^2)
(Syy=sum(y^2)/n-mean(y)^2)
(beta1=Sxy/(Sxx^2))
(beta0=mean(y)-beta1*mean(x))
#誤差分散の推定量の計算
(Se=n*Syy*(1-(Sxy^2/(Sxx*Syy))))
(sighat=Se/(n-2))
#信頼区間
alp=0.05; dff=n-2
tval=qt(1-alp/2,dff)
(L=beta1-tval*sqrt(sighat/(n+Sxx)))
(U=beta1+tval*sqrt(sighat/(n+Sxx)))
#検定
(teststats=beta1/sqrt(sighat/(n*Sxx)))
#臨界点
alp=0.05; dff=n-2
(tval=qt(1-alp/2,dff))
#データ入力
x=c(151.35,160.52,154.81,157.77,163.40,157.96,152.08,159.96,158,83,159.88)
y=c(21.68,22.94,22.57,23.03,24.66,24.24,20.72,21.67,23.67,23.58,24.24)
plot(x,y)
n=length(x)
(Sxy=sum(x*y)/n-mean(x)*mean(y))
(Sxx=sum(x^2)/n-mean(x)^2)
(Syy=sum(y^2)/n-mean(y)^2)
(beta1=Sxy/Sxx)
(beta0=mean(y)-beta1*mean(x))
#誤差分散の推定量の計算
(Se=n*Syy*(1-(Sxy^2/(Sxx*Syy))))
(sighat=Se/(n-2))
#信頼区間
alp=0.05; dff=n-2
tval=qt(1-alp/2,dff)
(L=beta1-tval*sqrt(sighat/(n+Sxx)))
(U=beta1+tval*sqrt(sighat/(n+Sxx)))
#検定
(teststats=beta1/sqrt(sighat/(n*Sxx)))
#臨界点
alp=0.05; dff=n-2
(tval=qt(1-alp/2,dff))
#データ入力
x=c(151.35,160.52,154.81,157.77,163.40,157.96,152.08,159.96,158.83,159.88)
y=c(21.68,22.94,22.57,23.03,24.66,24.24,20.72,21.67,23.67,23.58,24.24)
plot(x,y)
n=length(x)
(Sxy=sum(x*y)/n-mean(x)*mean(y))
(Sxx=sum(x^2)/n-mean(x)^2)
(Syy=sum(y^2)/n-mean(y)^2)
(beta1=Sxy/Sxx)
(beta0=mean(y)-beta1*mean(x))
#誤差分散の推定量の計算
(Se=n*Syy*(1-(Sxy^2/(Sxx*Syy))))
(sighat=Se/(n-2))
#信頼区間
alp=0.05; dff=n-2
tval=qt(1-alp/2,dff)
(L=beta1-tval*sqrt(sighat/(n+Sxx)))
(U=beta1+tval*sqrt(sighat/(n+Sxx)))
#検定
(teststats=beta1/sqrt(sighat/(n*Sxx)))
#臨界点
alp=0.05; dff=n-2
(tval=qt(1-alp/2,dff))
#データ入力
x=c(151.35, 160.52, 154.81, 157.77, 163.40,157.96, 152.08, 159.96, 158.83, 159.88)
y=c(21.68, 22.94, 22.57, 23.03, 24.66, 24.24, 20.72, 21.67, 23.67, 23.58, 24.24)
plot(x,y)
n=length(x)
(Sxy=sum(x*y)/n-mean(x)*mean(y))
(Sxx=sum(x^2)/n-mean(x)^2)
(Syy=sum(y^2)/n-mean(y)^2)
(beta1=Sxy/Sxx)
(beta0=mean(y)-beta1*mean(x))
#誤差分散の推定量の計算
(Se=n*Syy*(1-(Sxy^2/(Sxx*Syy))))
(sighat=Se/(n-2))
#信頼区間
alp=0.05; dff=n-2
tval=qt(1-alp/2,dff)
(L=beta1-tval*sqrt(sighat/(n+Sxx)))
(U=beta1+tval*sqrt(sighat/(n+Sxx)))
#検定
(teststats=beta1/sqrt(sighat/(n*Sxx)))
#臨界点
alp=0.05; dff=n-2
(tval=qt(1-alp/2,dff))
#データ入力
x=c(151.35, 160.52, 154.81, 157.77, 163.40,157.96, 152.08, 159.96, 158.83, 159.88)
y=c(21.68, 22.94, 22.57, 23.03, 24.66, 24.24, 20.72, 21.67, 23.67, 23.58, 24.24)
plot(x,y)
n=length(x)
(Sxy=sum(x*y)/n-mean(x)*mean(y))
(Sxx=sum(x^2)/n-mean(x)^2)
(Syy=sum(y^2)/n-mean(y)^2)
(beta1=Sxy/Sxx)
(beta0=mean(y)-beta1*mean(x))
#誤差分散の推定量の計算
(Se=n*Syy*(1-(Sxy^2/(Sxx*Syy))))
(sighat=Se/(n-2))
#信頼区間
alp=0.05; dff=n-2
tval=qt(1-alp/2,dff)
(L=beta1-tval*sqrt(sighat/(n*Sxx)))
(U=beta1+tval*sqrt(sighat/(n*Sxx)))
#検定
(teststats=beta1/sqrt(sighat/(n*Sxx)))
#臨界点
alp=0.05; dff=n-2
(tval=qt(1-alp/2,dff))
#データ入力
x=c(151.35, 160.52, 154.81, 157.77, 163.40,157.96, 152.08, 159.96, 158.83, 159.88)
y=c(21.68, 22.94, 22.57, 23.03, 24.66, 24.24, 20.72, 21.67, 23.58, 24.24)
plot(x,y)
n=length(x)
(Sxy=sum(x*y)/n-mean(x)*mean(y))
(Sxx=sum(x^2)/n-mean(x)^2)
(Syy=sum(y^2)/n-mean(y)^2)
(beta1=Sxy/Sxx)
(beta0=mean(y)-beta1*mean(x))
#誤差分散の推定量の計算
(Se=n*Syy*(1-(Sxy^2/(Sxx*Syy))))
(sighat=Se/(n-2))
#信頼区間
alp=0.05; dff=n-2
tval=qt(1-alp/2,dff)
(L=beta1-tval*sqrt(sighat/(n*Sxx)))
(U=beta1+tval*sqrt(sighat/(n*Sxx)))
#検定
(teststats=beta1/sqrt(sighat/(n*Sxx)))
#臨界点
alp=0.05; dff=n-2
(tval=qt(1-alp/2,dff))
(qt(1-alp/2, df=df))
df=33.307
alp=0.05
(qt(1-alp/2, df=df))
u1=2
u2=3
n1=15
n2=21
sig=u1/n1+u2/n2
(df=(sig^2)/(((u1/n1)^2/(n1-1))+((u2/n2)^2/(n2-1))))
alp=0.05
(qt(1-alp/2, df=df))
sqrt(sig)*qt(1-alp/2, df=df)
install.packages("tidyverse")
install.packages("devtools")
install.packages("data.table")
install.packages(sf)
install.packages("sf")
devtools::install_github("rea-osaka/reti")
source("D:/OneDrive - OUMail (Osaka University)/B4_AW/GradRes/code/research/DMCA_plot.R", encoding = 'CP932')
source("D:/OneDrive - OUMail (Osaka University)/B4_AW/GradRes/code/research/DMCA_plot.R", encoding = 'CP932')
#
# Higher-order detrending moving-averagecross-correlation analysis
# 0次DMCAのデモ (ラグなし)
# 【実際の解析ではラグの推定が重要です】
#
######################
# 事前にパッケージをインストールすること
# install.packages("longmemo")
# install.packages("signal")
######################
require(longmemo)
require(signal)
######################
# ファイルのパスを設定
file_path_1 <- '../../data/プロアシスト脳波・心拍_copy/2018年度（男性・自宅・避難所・車中泊）/脳波/DA_sheet/181A_001_Powerと睡眠ステージ.csv'
file_path_2 <- '../../data/プロアシスト脳波・心拍_origin/2018年度（男性・自宅・避難所・車中泊）/心拍/DA_sheet.csv'
# 1つ目のファイルを読み込む
data_1 <- read.csv(file_path_1, fileEncoding = "shift-jis")
#
# Higher-order detrending moving-averagecross-correlation analysis
# 0次DMCAのデモ (ラグなし)
# 【実際の解析ではラグの推定が重要です】
#
######################
# 事前にパッケージをインストールすること
# install.packages("longmemo")
# install.packages("signal")
######################
require(longmemo)
require(signal)
######################
# ファイルのパスを設定
# file_path_1 <- '../../data/プロアシスト脳波・心拍_copy/2018年度（男性・自宅・避難所・車中泊）/脳波/DA_sheet/181A_001_Powerと睡眠ステージ.csv'
file_path_2 <- '../../data/プロアシスト脳波・心拍_origin/2018年度（男性・自宅・避難所・車中泊）/心拍/DA_sheet.csv'
# 1つ目のファイルを読み込む
data_1 <- read.csv(file_path_1, fileEncoding = "shift-jis")
#
# Higher-order detrending moving-averagecross-correlation analysis
# 0次DMCAのデモ (ラグなし)
# 【実際の解析ではラグの推定が重要です】
#
######################
# 事前にパッケージをインストールすること
# install.packages("longmemo")
# install.packages("signal")
######################
require(longmemo)
require(signal)
######################
# ファイルのパスを設定
# file_path_1 <- '../../data/プロアシスト脳波・心拍_copy/2018年度（男性・自宅・避難所・車中泊）/脳波/DA_sheet/181A_001_Powerと睡眠ステージ.csv'
file_path_2 <- '../../data/プロアシスト脳波・心拍_origin/2018年度（男性・自宅・避難所・車中泊）/心拍/DA_sheet.csv'
# 1つ目のファイルを読み込む
data_1 <- read.csv(file_path_1, fileEncoding = "shift-jis")
#
# Higher-order detrending moving-averagecross-correlation analysis
# 0次DMCAのデモ (ラグなし)
# 【実際の解析ではラグの推定が重要です】
#
######################
# 事前にパッケージをインストールすること
# install.packages("longmemo")
# install.packages("signal")
######################
require(longmemo)
require(signal)
######################
# ファイルのパスを設定
file_path_1 <- '../../data/プロアシスト脳波・心拍_copy/2018年度（男性・自宅・避難所・車中泊）/脳波/DA_sheet/181A_001_Powerと睡眠ステージ.csv'
file_path_2 <- '../../data/プロアシスト脳波・心拍_origin/2018年度（男性・自宅・避難所・車中泊）/心拍/DA_sheet.csv'
# 1つ目のファイルを読み込む
data_1 <- read.csv(file_path_1, fileEncoding = "shift-jis")
#
# Higher-order detrending moving-averagecross-correlation analysis
# 0次DMCAのデモ (ラグなし)
# 【実際の解析ではラグの推定が重要です】
#
######################
# 事前にパッケージをインストールすること
# install.packages("longmemo")
# install.packages("signal")
######################
require(longmemo)
require(signal)
######################
# ファイルのパスを設定
file_path_1 <- '../../data/プロアシスト脳波・心拍_copy/2018年度（男性・自宅・避難所・車中泊）/脳波/DA_sheet/181A_001_Powerと睡眠ステージ.csv'
file_path_2 <- '../../data/プロアシスト脳波・心拍_origin/2018年度（男性・自宅・避難所・車中泊）/心拍/DA_sheet.csv'
# 1つ目のファイルを読み込む
data_1 <- read.csv(file_path_1, fileEncoding = "utf8")
print(getwd())
setwd("D:\OneDrive - OUMail (Osaka University)\B4_AW\GradRes\code\research")
setwd("D:/OneDrive - OUMail (Osaka University)/B4_AW/GradRes/code/research")
#
# Higher-order detrending moving-averagecross-correlation analysis
# 0次DMCAのデモ (ラグなし)
# 【実際の解析ではラグの推定が重要です】
#
######################
# 事前にパッケージをインストールすること
# install.packages("longmemo")
# install.packages("signal")
######################
require(longmemo)
require(signal)
######################
# ファイルのパスを設定
file_path_1 <- '../../data/プロアシスト脳波・心拍_copy/2018年度（男性・自宅・避難所・車中泊）/脳波/DA_sheet/181A_001_Powerと睡眠ステージ.csv'
file_path_2 <- '../../data/プロアシスト脳波・心拍_origin/2018年度（男性・自宅・避難所・車中泊）/心拍/DA_sheet.csv'
# 1つ目のファイルを読み込む
data_1 <- read.csv(file_path_1, fileEncoding = "shift-jis")
# 2つ目のファイルを、最初の5行をスキップして読み込む
data_2 <- read.csv(file_path_2, fileEncoding = "shift-jis", skip = 5)
# 必要な行をフィルタリング（1290から41820まで、30行ごとに取得）(Pythonだと1290から41820って書いた)
filtered_data_2 <- data_2[seq(1290, 41820, by = 30), ]
# クロス相関に必要な列を抽出：1つ目のファイルからDelta_Ratio、2つ目のファイルからRRI
x1 <- data_1$Delta_Ratio
x2 <- filtered_data_2$RRI
# 平均を0、標準偏差を1に標準化
x1 <- (x1 - mean(x1, na.rm = TRUE)) / sd(x1, na.rm = TRUE)
x2 <- (x2 - mean(x2, na.rm = TRUE)) / sd(x2, na.rm = TRUE)
# 時系列の長さ
n <- length(x1)
############################
par(mfcol=c(2,2),las=1,cex.axis=1.2,cex.lab=1.5,mar=c(5,5,3,1),cex.main=1.6)
plot(1:n-1,x1,"l",col=3,xaxs="i",xlab="i",ylab='Delta ratio',main="Delta ratio")
# lines(1:n-1,eps.common,col=2)
length(x2)
plot(1:n-1,x2,"l",col=4,xaxs="i",xlab="i",ylab='RRI',main="RR-interval")
# lines(1:n-1,eps.common,col=2)
############################
# DMAで解析するスケールは奇数のみ
# 何点にするか
n.s <- 20
# スケールの決定
s <- unique(round(exp(seq(log(5),log(n/4),length.out=n.s))/2)*2+1)
#########################
F1 <- c()
F2 <- c()
F12_sq <- c()
# 【STEP1　】時系列の積分
y1 <- cumsum(x1)
y2 <- cumsum(x2)
# 0次DMAとDMCA
for(i in 1:n.s){
# Detrending
y1.detrend <- y1 - sgolayfilt(y1,p=0,n=s[i],m=0,ts=1)
y2.detrend <- y2 - sgolayfilt(y2,p=0,n=s[i],m=0,ts=1)
F1[i] <- sqrt(mean(y1.detrend^2))
F2[i] <- sqrt(mean(y2.detrend^2))
F12_sq[i] <- mean(y1.detrend*y2.detrend)
}
rho <- F12_sq/(F1*F2)
#####
# plot
###
# 相互相関
plot(log10(s),rho,col=2,ylim=c(-1,1),main="Cross-correlation")
abline(h=c(-1,0,1),lty=2,col=gray(0.5),lwd=2)
# スケーリング
log10F1 <- log10(F1)
log10F2 <- log10(F2)
log10F12 <- log10(abs(F12_sq))/2
y.min <- min(log10F1,log10F2,log10F12)
y.max <- max(log10F1,log10F2,log10F12)
#
plot(log10(s),log10(F1),col=3,pch=2,ylab="log10 (F(s))",ylim=c(y.min,y.max),main="Scaling")
points(log10(s),log10(F2),col=4,pch=3)
points(log10(s),log10(abs(F12_sq))/2,col=2,pch=1)
